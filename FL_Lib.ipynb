{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f460af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "564276d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minstIID(dataset, num_users):\n",
    "    num_images = int(len(dataset)/num_users)\n",
    "    users_dict, indeces = {}, list(range(len(dataset)))\n",
    "    for i in range(num_users):\n",
    "        np.random.seed(i) # to expect the same random value each time of running  the code\n",
    "        users_dict[i] = set(np.random.choice(indeces,num_images,replace=False))\n",
    "        indeces = list(set(indeces) - users_dict[i]) # remove used indeces from main indeces\n",
    "    return users_dict\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dc79c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minstNonIID(dataset, num_users):\n",
    "    # define the number of classes and images per class\n",
    "    classes, images = 100, 600\n",
    "    \n",
    "    # set classess indecies\n",
    "    classes_indx = [i for i in range(classes)]\n",
    "    \n",
    "    # initlize user dict by user number\n",
    "    users_dict = {i: np.array([]) for i in range(num_users)}\n",
    "    \n",
    "    #define indeces\n",
    "    indeces = classes * images # 60K which is the number of total images\n",
    "    \n",
    "    # define unsorted labels\n",
    "    unsorted_labels = dataset.train_labels.numpy()\n",
    "    \n",
    "    # define vertical stack \n",
    "    indeces_unlabels = np.vstack((indeces, unsorted_labels))\n",
    "    \n",
    "    # sort labels \n",
    "    indeces_sortedlabels = indeces_unlabels[:,indeces_unlabels[1,:].argsort()]\n",
    "    \n",
    "    indeces = indeces_sortedlabels[0,:] # indeces of sorted labels\n",
    "    \n",
    "    # Define each user its classes and images\n",
    "    # define it randomly 2 classes and set it images\n",
    "    for i in range(num_users):\n",
    "        np.random.seed(i) # to expect the same random value each time of running  the code\n",
    "        temp = set(np.random.choice(classes_indx,2,replace=False))\n",
    "        classes_indx = list(set(classes_indx) - temp)\n",
    "        for t in temp:\n",
    "            users_dict[i] = np.concatenate((users_dict[i], indeces[t*images : (t+1)*images]),axis=0)\n",
    "    \n",
    "    return users_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a75453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minstNonIIDUnequal(dataset, num_users):\n",
    "    # define the number of classes and images per class\n",
    "    classes, images = 1200, 50 # shall be 60k\n",
    "    \n",
    "    # set classess indecies\n",
    "    classes_indx = [i for i in range(classes)]\n",
    "    \n",
    "    # initlize user dict by user number\n",
    "    users_dict = {i: np.array([]) for i in range(num_users)}\n",
    "    \n",
    "    #define indeces\n",
    "    indeces = no.arange(classes * images) # 60K which is the number of total images\n",
    "    \n",
    "    # define unsorted labels\n",
    "    unsorted_labels = dataset.train_labels.numpy()\n",
    "    \n",
    "    # define vertical stack \n",
    "    indeces_unlabels = np.vstack((indeces, unsorted_labels))\n",
    "    \n",
    "    # sort labels \n",
    "    indeces_sortedlabels = indeces_unlabels[:,indeces_unlabels[1,:].argsort()]\n",
    "    \n",
    "    indeces = indeces_sortedlabels[0,:] # indeces of sorted labels\n",
    "    \n",
    "    # Here the unbalance of the selecting the classes and number of classes,\n",
    "    # but each client at least has one class\n",
    "    \n",
    "    min_cls_per_client = 1\n",
    "    max_cls_per_client = 30\n",
    "    \n",
    "    # generate 10 (user number) random values\n",
    "    random_selected_classes = np.random.tint(min_cls_per_client,max_cls_per_client+1,size=num_users)\n",
    "    \n",
    "    # calculate percentage of selected classes\n",
    "    ratio_selected = sum(random_selected_classes) / classes # example 0.5 means onlt halfis used\n",
    "    \n",
    "    # so we are going to increase same selected number by the same ratio so that we reached 100%\n",
    "    \n",
    "    random_selected_classes = np.around(random_selected_classes/ratio_selected)\n",
    "    \n",
    "    # make it int\n",
    "    random_selected_classes = random_selected_classes.astype(int)\n",
    "    \n",
    "    # Now there is two cases due to round up that we exceed the total number of classes allowed\n",
    "    # or due to round , still some classes not selected\n",
    "    \n",
    "    # let us start by the first case\n",
    "    \n",
    "    if sum(random_selected_classes) > classes:\n",
    "        \n",
    "        # for each user select at least one class\n",
    "        for i in range(num_users):\n",
    "            temp = set(np.random.choice(classes_indx,1,replace=False))\n",
    "            \n",
    "            # subtract the selected claess from main list\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            \n",
    "            # For the seelected clasess concatenate the indeces of the images\n",
    "            # where start by each selected till number of images (50)\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indeces[t*images:(t+1)*images]),axis=0)\n",
    "    \n",
    "        # subtract for all the user one allocated class\n",
    "        random_selected_classes = random_selected_classes-1\n",
    "        \n",
    "        # now we will loop in each user give him his selected classes, till we \n",
    "        # reach the last one , will take only the remaining of the classes\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            if len(classes_indx) == 0:\n",
    "                continue\n",
    "            # here asign the selected user his random selected classes\n",
    "            class_size = random_selected_classes[i]\n",
    "            \n",
    "            # check if we reach the end of the classes allocation\n",
    "            if class_size > len(classes_indx):\n",
    "                class_size = len(classes_indx)\n",
    "            \n",
    "            # set the seed for chosing randomly the classes\n",
    "            np.random.seed(i)\n",
    "            temp = set(np.random.chioce(classes_indx,class_size,replace=False))\n",
    "            \n",
    "            # subtract the temp from main classes\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            \n",
    "            # concatenate all the images indeces to the user\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indeces[t*images:(t+1)*images]),axis=0)\n",
    "            # Finish case random selected > clasess\n",
    "    \n",
    "    else: # case random selected <= classes\n",
    "            \n",
    "        # give each user its random selected\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            \n",
    "            class_size = random_selected_classes[i]\n",
    "            np.random.seed(i)\n",
    "            \n",
    "            temp = set(np.random.choice(classes_indx,class_size,replace=False))\n",
    "            \n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            \n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i],indeces[t*images:(t+1)*images]),axis=0)\n",
    "                \n",
    "        # Now we assign each user by reandom selected classes\n",
    "        # check if there are remaining classes not selected\n",
    "        \n",
    "        if len(classes_indx) > 0:\n",
    "            class_size = len(classes_indx)\n",
    "            \n",
    "            # assign the remaining clasess to the user that have min classes \"fair :D\"\n",
    "            \n",
    "            j = min(users_dict, key=lambda x: len(users_dict.get(x)))\n",
    "            \n",
    "            temp = set(np.random.choice(classes_indx,class_size,replace=False))\n",
    "            \n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            \n",
    "            assert len(classes_indx) == 0\n",
    "            \n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[j], indeces[t*images:(t+1)*images]),axis=0)\n",
    "            # finish case random < classes\n",
    "            \n",
    "    return users_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a8f1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_dataset(num_users, iidtype):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "    train_dataset = torchvision.datasets.MNIST(root = \"./data\", train = True, transform = transform, target_transform = None, download = True)\n",
    "    test_dataset = torchvision.datasets.MNIST(root = \"./data\", train = False, transform = transform, target_transform = None, download = True)\n",
    "    \n",
    "    if iidtype == 'iid':\n",
    "        train_group = minstIID(train_dataset, num_users)\n",
    "        test_group = minstIID(test_dataset, num_users)\n",
    "    elif iidtype == 'noniid':\n",
    "        train_group = minstNonIID(train_dataset, num_users)\n",
    "        test_group = minstNonIID(test_dataset, num_users)\n",
    "    else:\n",
    "        train_group = minstNonIIDUnequal(train_dataset, num_users)\n",
    "        test_group = minstIIDUnequal(test_dataset, num_users)\n",
    "    return train_dataset, test_dataset, train_group, test_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b73a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1bdb2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3682b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedDataset(Dataset):\n",
    "    def __init__(self,dataset,indx):\n",
    "        self.dataset = dataset\n",
    "        self.indx = [int(i) for i in indx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indx)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        images,label = self.dataset[self.indx[item]]\n",
    "        #return torch.tensor(images),torch.tensor(label)\n",
    "        return torch.tensor(images).clone().detach(), torch.tensor(label).clone().detach()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f658f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActualImgs(dataset, indeces, batch_size):\n",
    "    return DataLoader(FedDataset(dataset,indeces), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a74ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
